# automatically generated by the FlatBuffers compiler, do not modify

# namespace: hcf

import flatbuffers
from flatbuffers.compat import import_numpy
from typing import Any
from typing import Optional
np = import_numpy()

class FlatTensorBatch(object):
    __slots__ = ['_tab']

    @classmethod
    def GetRootAs(cls, buf, offset: int = 0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)
        x = FlatTensorBatch()
        x.Init(buf, n + offset)
        return x

    @classmethod
    def GetRootAsFlatTensorBatch(cls, buf, offset=0):
        """This method is deprecated. Please switch to GetRootAs."""
        return cls.GetRootAs(buf, offset)
    # FlatTensorBatch
    def Init(self, buf: bytes, pos: int):
        self._tab = flatbuffers.table.Table(buf, pos)

    # FlatTensorBatch
    def Id(self) -> Optional[str]:
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            return self._tab.String(o + self._tab.Pos)
        return None

    # FlatTensorBatch
    def Tensor(self, j: int):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            a = self._tab.Vector(o)
            return self._tab.Get(flatbuffers.number_types.Float32Flags, a + flatbuffers.number_types.UOffsetTFlags.py_type(j * 4))
        return 0

    # FlatTensorBatch
    def TensorAsNumpy(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            return self._tab.GetVectorAsNumpy(flatbuffers.number_types.Float32Flags, o)
        return 0

    # FlatTensorBatch
    def TensorLength(self) -> int:
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            return self._tab.VectorLen(o)
        return 0

    # FlatTensorBatch
    def TensorIsNone(self) -> bool:
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        return o == 0

    # FlatTensorBatch
    def Dim(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(8))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int32Flags, o + self._tab.Pos)
        return 0

    # FlatTensorBatch
    def Type(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(10))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int8Flags, o + self._tab.Pos)
        return 0

def FlatTensorBatchStart(builder: flatbuffers.Builder):
    builder.StartObject(4)

def Start(builder: flatbuffers.Builder):
    FlatTensorBatchStart(builder)

def FlatTensorBatchAddId(builder: flatbuffers.Builder, id: int):
    builder.PrependUOffsetTRelativeSlot(0, flatbuffers.number_types.UOffsetTFlags.py_type(id), 0)

def AddId(builder: flatbuffers.Builder, id: int):
    FlatTensorBatchAddId(builder, id)

def FlatTensorBatchAddTensor(builder: flatbuffers.Builder, tensor: int):
    builder.PrependUOffsetTRelativeSlot(1, flatbuffers.number_types.UOffsetTFlags.py_type(tensor), 0)

def AddTensor(builder: flatbuffers.Builder, tensor: int):
    FlatTensorBatchAddTensor(builder, tensor)

def FlatTensorBatchStartTensorVector(builder, numElems: int) -> int:
    return builder.StartVector(4, numElems, 4)

def StartTensorVector(builder, numElems: int) -> int:
    return FlatTensorBatchStartTensorVector(builder, numElems)

def FlatTensorBatchAddDim(builder: flatbuffers.Builder, dim: int):
    builder.PrependInt32Slot(2, dim, 0)

def AddDim(builder: flatbuffers.Builder, dim: int):
    FlatTensorBatchAddDim(builder, dim)

def FlatTensorBatchAddType(builder: flatbuffers.Builder, type: int):
    builder.PrependInt8Slot(3, type, 0)

def AddType(builder: flatbuffers.Builder, type: int):
    FlatTensorBatchAddType(builder, type)

def FlatTensorBatchEnd(builder: flatbuffers.Builder) -> int:
    return builder.EndObject()

def End(builder: flatbuffers.Builder) -> int:
    return FlatTensorBatchEnd(builder)

try:
    from typing import List
except:
    pass

class FlatTensorBatchT(object):

    # FlatTensorBatchT
    def __init__(self):
        self.id = None  # type: str
        self.tensor = None  # type: List[float]
        self.dim = 0  # type: int
        self.type = 0  # type: int

    @classmethod
    def InitFromBuf(cls, buf, pos):
        flatTensorBatch = FlatTensorBatch()
        flatTensorBatch.Init(buf, pos)
        return cls.InitFromObj(flatTensorBatch)

    @classmethod
    def InitFromPackedBuf(cls, buf, pos=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, pos)
        return cls.InitFromBuf(buf, pos+n)

    @classmethod
    def InitFromObj(cls, flatTensorBatch):
        x = FlatTensorBatchT()
        x._UnPack(flatTensorBatch)
        return x

    # FlatTensorBatchT
    def _UnPack(self, flatTensorBatch):
        if flatTensorBatch is None:
            return
        self.id = flatTensorBatch.Id()
        if not flatTensorBatch.TensorIsNone():
            if np is None:
                self.tensor = []
                for i in range(flatTensorBatch.TensorLength()):
                    self.tensor.append(flatTensorBatch.Tensor(i))
            else:
                self.tensor = flatTensorBatch.TensorAsNumpy()
        self.dim = flatTensorBatch.Dim()
        self.type = flatTensorBatch.Type()

    # FlatTensorBatchT
    def Pack(self, builder):
        if self.id is not None:
            id = builder.CreateString(self.id)
        if self.tensor is not None:
            if np is not None and type(self.tensor) is np.ndarray:
                tensor = builder.CreateNumpyVector(self.tensor)
            else:
                FlatTensorBatchStartTensorVector(builder, len(self.tensor))
                for i in reversed(range(len(self.tensor))):
                    builder.PrependFloat32(self.tensor[i])
                tensor = builder.EndVector()
        FlatTensorBatchStart(builder)
        if self.id is not None:
            FlatTensorBatchAddId(builder, id)
        if self.tensor is not None:
            FlatTensorBatchAddTensor(builder, tensor)
        FlatTensorBatchAddDim(builder, self.dim)
        FlatTensorBatchAddType(builder, self.type)
        flatTensorBatch = FlatTensorBatchEnd(builder)
        return flatTensorBatch
